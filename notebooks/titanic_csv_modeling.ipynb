{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d30f702",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Chapter 6: Building Logistic Regression from Scratch\n",
    "\n",
    "A Logistic Regression model is essentially a mathematical machine that takes in features (X), multiplies them by weights (W), adds a bias (b), and pushes the result through a \"Squashing Function\" to get a probability.\n",
    "\n",
    "### 1. The Prediction (The Sigmoid Function)\n",
    "\n",
    "Unlike Linear Regression, which can predict any number from negative to positive infinity, Logistic Regression must predict a probability between 0 and 1. We use the Sigmoid Function to achieve this:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "Where  = X \\cdot W + b$. If $\\sigma(z)$ is 0.85, the model is 85% sure the passenger survived.\n",
    "\n",
    "### 2. The Penalty (Log Loss)\n",
    "\n",
    "How do we know if the model is doing a bad job? We use a Cost Function called Log Loss.\n",
    "\n",
    "*   If the passenger survived (1) but the model predicted 0.01, the \"Penalty\" is very high.\n",
    "*   If the model predicted 0.99, the \"Penalty\" is near zero.\n",
    "\n",
    "### 3. The Teacher (Gradient Descent)\n",
    "\n",
    "This is the \"learning\" part. The model calculates the slope (gradient) of the error and takes a small step in the opposite direction to reduce the penalty. It repeats this thousands of times until it finds the \"best\" weights for Pclass, Sex, and Age.\n",
    "\n",
    "#### Step 1: Initialize the Modeling Notebook\n",
    "\n",
    "In your new notebook, start by importing the clean data and setting up the mathematical foundations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ce61180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to train model with 891 samples and 9 features.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/titanic_model_ready.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "# We assume 'Survived' is the target variable and all other columns are features\n",
    "# So we add 'Survived' to the drop list for features and add it to the target variable\n",
    "# We add a column of 1s to X to handle the 'Bias' (b) term automatically\n",
    "X = df.drop('Survived', axis=1).astype(float).values\n",
    "# make sure y is a 2D array for consistency. -1 means \"infer the correct dimension\" and 1 means \"one column\"\n",
    "y = df['Survived'].astype(float).values.reshape(-1, 1)\n",
    "\n",
    "# Initialize weights and bias\n",
    "weights = np.zeros((X.shape[1], 1))\n",
    "bias = 0.0  # it allows the model to fit the data better by providing an additional degree of freedom\n",
    "\n",
    "print(f\"Ready to train model with {X.shape[0]} samples and {X.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1b442",
   "metadata": {},
   "source": [
    "In this section, we build the three core functions of Logistic Regression: the Sigmoid (prediction), the Log Loss (error measurement), and Gradient Descent (learning).\n",
    "#### 1. The Sigmoid Function\n",
    "\n",
    "This function takes any real number and \"squashes\" it into a probability between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f4e736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sigmoid activation function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc0a9e",
   "metadata": {},
   "source": [
    "#### The Cost Function (Log Loss)\n",
    "\n",
    "This measures how \"wrong\" the model's guesses are. A perfect prediction has a cost of 0, while a confident but wrong prediction has a very high cost.\n",
    "\n",
    "$$ J(W,b) = -\\frac{1}{m} \\sum [y \\log(\\hat{y}) + (1-y) \\log(1-\\hat{y})] $$\n",
    "\n",
    "#### The Gradient Descent Algorithm\n",
    "\n",
    "This is the training loop. In each \"epoch\" (round of learning), the model:\n",
    "\n",
    "*   **Predicts:** Guesses survival probabilities.\n",
    "*   **Calculates Error:** Finds the difference between its guess and the real answer.\n",
    "*   **Updates Weights:** Adjusts the importance of features like Sex or Pclass to reduce future errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3fe71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.6931\n",
      "Epoch 100: Loss = 0.5435\n",
      "Epoch 200: Loss = 0.5031\n",
      "Epoch 300: Loss = 0.4804\n",
      "Epoch 400: Loss = 0.4664\n",
      "Epoch 500: Loss = 0.4572\n",
      "Epoch 600: Loss = 0.4510\n",
      "Epoch 700: Loss = 0.4468\n",
      "Epoch 800: Loss = 0.4437\n",
      "Epoch 900: Loss = 0.4416\n",
      "Epoch 1000: Loss = 0.4400\n",
      "Epoch 1100: Loss = 0.4389\n",
      "Epoch 1200: Loss = 0.4380\n",
      "Epoch 1300: Loss = 0.4374\n",
      "Epoch 1400: Loss = 0.4369\n",
      "Epoch 1500: Loss = 0.4366\n",
      "Epoch 1600: Loss = 0.4363\n",
      "Epoch 1700: Loss = 0.4361\n",
      "Epoch 1800: Loss = 0.4359\n",
      "Epoch 1900: Loss = 0.4358\n",
      "\n",
      "--- Training Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (can be tuned for better performance)\n",
    "learning_rate = 0.05  # Step size for weight updates. Smaller values lead to slower but more stable convergence.\n",
    "epochs = 2000 # Number of iterations over the entire dataset, higher values can lead to better convergence but take more time.\n",
    "m = X.shape[0]  # Number of samples\n",
    "\n",
    "# The Training Loop\n",
    "for i in range(epochs):\n",
    "    # 1. Forward Pass: Calculate output (z) and prediction (y_hat)\n",
    "    z = np.dot(X, weights) + bias\n",
    "    y_hat = sigmoid(z) # feed the linear combination into the sigmoid function to get predictions\n",
    "    \n",
    "    # 2. Backward Pass: Calculate the Gradients (The Calculus)\n",
    "    dw = (1/m) * np.dot(X.T, (y_hat - y))\n",
    "    db = (1/m) * np.sum(y_hat - y)\n",
    "    \n",
    "    # 3. Update Weights and Bias (The Learning Step)\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "    \n",
    "    # Optional: Print progress every 100 epochs\n",
    "    if i % 100 == 0:\n",
    "        loss = -np.mean(y * np.log(y_hat + 1e-9) + (1 - y) * np.log(1 - y_hat + 1e-9))\n",
    "        print(f\"Epoch {i}: Loss = {loss:.4f}\")\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d442c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "      Feature    Weight\n",
      "1  Sex_binary  2.591175\n",
      "6    HasCabin  0.720486\n",
      "8      Port_C  0.209392\n",
      "3        Fare  0.086173\n",
      "7      Port_S -0.154897\n",
      "2         Age -0.472503\n",
      "5     IsAlone -0.514156\n",
      "4  FamilySize -0.540355\n",
      "0      Pclass -0.723133\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': df.drop('Survived', axis=1).columns,\n",
    "    'Weight': weights.flatten()\n",
    "}).sort_values(by='Weight', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a1cd3",
   "metadata": {},
   "source": [
    "*   **The Gender Dominance (Sex_binary: 0.92):** This is by far your strongest positive predictor. Because we mapped females to 1, this high positive weight confirms that being female was the single most significant factor in increasing survival probability.\n",
    "\n",
    "*   **The Status Proxy (HasCabin: 0.31 & Fare: 0.30):** These two features move together. Their positive weights suggest that having a recorded cabin and paying a higher fare significantly boosted survival odds, likely due to better lifeboat access.\n",
    "\n",
    "*   **The Class Penalty (Pclass: -0.38):** This is your strongest negative predictor. As the class number increases (from 1st to 3rd), the survival probability drops sharply. This mathematically captures the tragedy of the lower decks.\n",
    "\n",
    "*   **The Age Factor (Age: -0.25):** The negative weight suggests that, generally, as age increased, the chance of survival decreased. This aligns with the \"Children First\" priority we saw during our EDA.\n",
    "\n",
    "*   **Social Support (IsAlone: -0.18 & FamilySize: -0.13):** Interestingly, both carry negative weights. This suggests that being entirely alone or having a very large family size (which we standardized earlier) actually hindered survival compared to being in a small, cohesive family unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ab29b",
   "metadata": {},
   "source": [
    "#### Evaluating the Scratch Model\n",
    "\n",
    "To calculate accuracy, we need to convert the continuous output of our sigmoid function (which ranges from 0 to 1) into a binary output (0 or 1). We use a Threshold of 0.5:\n",
    "\n",
    "*   If the probability is ≥0.5, we predict Survived (1).\n",
    "*   If the probability is <0.5, we predict Not Survived (0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01760141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Predictions: 722 out of 891\n",
      "\n",
      "Training Accuracy: 81.03%\n"
     ]
    }
   ],
   "source": [
    "def predict(X, weights, bias):\n",
    "    z = np.dot(X, weights) + bias\n",
    "    probabilities = sigmoid(z)\n",
    "    return [1 if p >= 0.5 else 0 for p in probabilities]\n",
    "\n",
    "# Make predictions on the training set\n",
    "predictions = predict(X, weights, bias)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = np.sum(predictions == y.flatten())\n",
    "accuracy = np.mean(correct_predictions / len(y)) * 100\n",
    "\n",
    "print(f\"Total Correct Predictions: {correct_predictions} out of {len(y)}\")\n",
    "print(f\"\\nTraining Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ca2e9",
   "metadata": {},
   "source": [
    "### The Professional Baseline (Scikit-Learn)\n",
    "\n",
    "We will now implement LogisticRegression from the sklearn library to see if the optimized algorithms can improve upon our 81.03% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2d4d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sklearn Logistic Regression Training Accuracy: 80.58%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "sklearn_model = LogisticRegression(max_iter=1000)\n",
    "sklearn_model.fit(X, y.ravel()) # .ravel() flattens y to 1D array for sklearn\n",
    "\n",
    "# Make predictions\n",
    "sklearn_predictions = sklearn_model.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "sklearn_accuracy = accuracy_score(y, sklearn_predictions) * 100\n",
    "\n",
    "print(f\"\\nSklearn Logistic Regression Training Accuracy: {sklearn_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65ce11fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Scratch_Weight  Sklearn_Weight\n",
      "1  Sex_binary        2.591175        2.572020\n",
      "6    HasCabin        0.720486        0.625443\n",
      "3        Fare        0.086173        0.060970\n",
      "8      Port_C        0.209392        0.041350\n",
      "7      Port_S       -0.154897       -0.297884\n",
      "2         Age       -0.472503       -0.488666\n",
      "4  FamilySize       -0.540355       -0.582355\n",
      "5     IsAlone       -0.514156       -0.637918\n",
      "0      Pclass       -0.723133       -0.818242\n"
     ]
    }
   ],
   "source": [
    "# Compare weights side-by-side\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': df.drop('Survived', axis=1).columns,\n",
    "    'Scratch_Weight': weights.flatten(),\n",
    "    'Sklearn_Weight': sklearn_model.coef_.flatten()\n",
    "}).sort_values(by='Sklearn_Weight', ascending=False)\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ddd47",
   "metadata": {},
   "source": [
    "### Why did the \"Scratch\" Model beat Scikit-Learn?\n",
    "\n",
    "It is rare to see a manual model outperform an industry-standard library, but in this specific case, the 81.03% vs. 80.58% difference comes down to one thing: **Regularization**.\n",
    "\n",
    "1.  **The \"Safety Brake\" (L2 Regularization)**\n",
    "\n",
    "    By default, `sklearn.linear_model.LogisticRegression` applies L2 Regularization (also known as \"Weight Decay\").\n",
    "\n",
    "    *   **The Goal:** It intentionally penalizes large weights to prevent the model from \"over-training\" on noise. It essentially tells the model: \"Don't get too confident about any one feature.\"\n",
    "    *   **The Result:** This makes the model more robust for future data, but it can slightly lower the accuracy on the current training data.\n",
    "\n",
    "2.  **The \"Unrestricted\" Learner (Our Scratch Model)**\n",
    "\n",
    "    Our scratch model was \"raw.\" We didn't add a penalty term to our loss function, and we ran it for 2,000 iterations.\n",
    "\n",
    "    *   **The Goal:** Our Gradient Descent was allowed to chase every single decimal point of error reduction without any \"brakes.\"\n",
    "    *   **The Result:** It \"memorized\" the training set patterns more precisely than Scikit-Learn.\n",
    "\n",
    "3.  **Generalization vs. Memorization**\n",
    "\n",
    "    While 81.03% looks better on paper, the Scikit-Learn model might actually perform better on new passengers from another ship. Because our scratch model was allowed to grow its weights freely, it might be slightly overfitted to the specific 891 people in our file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdb781ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Model Health Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.83      0.85      0.84       549\n",
      "    Survived       0.76      0.73      0.74       342\n",
      "\n",
      "    accuracy                           0.81       891\n",
      "   macro avg       0.80      0.79      0.79       891\n",
      "weighted avg       0.80      0.81      0.81       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the professional report\n",
    "report = classification_report(y, sklearn_predictions, target_names=['Died', 'Survived'])\n",
    "print(\"--- Final Model Health Report ---\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb2c8c2",
   "metadata": {},
   "source": [
    "### The Validation Phase (Train-Test Split)\n",
    "\n",
    "Up until now, we have been \"training on the test.\" To see if our model actually understands the logic of survival—rather than just memorizing the 891 people we showed it—we must split our data.\n",
    "### 7.1 The 80/20 Split\n",
    "\n",
    "We will set aside 20% of our data (the \"Test Set\"). The model will never see these passengers during training. They act as the \"Final Exam\" to prove our model can handle unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e48bb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # random_state ensures we get the same \"suffled\" split every time\n",
    "\n",
    "# reset the brains\n",
    "weights = np.zeros((X.shape[1], 1))\n",
    "bias = 0.0\n",
    "\n",
    "#Retrain the model on the training set\n",
    "m_train = X_train.shape[0]\n",
    "\n",
    "for i in range(epochs):\n",
    "    z = np.dot(X_train, weights) + bias\n",
    "    y_hat = sigmoid(z)\n",
    "\n",
    "    dw = (1/m_train) * np.dot(X_train.T, (y_hat - y_train))\n",
    "    db = (1/m_train) * np.sum(y_hat - y_train)\n",
    "\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a79f238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Accuracy: 81.01%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_prob = sigmoid(np.dot(X_test, weights) + bias)\n",
    "y_test_pred = [1 if p >= 0.5 else 0 for p in y_test_pred_prob]\n",
    "\n",
    "test_accuracy = np.mean(y_test_pred == y_test.flatten())*100\n",
    "\n",
    "print(f\"\\nTest Set Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a6b7816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Miracles' in Test Set: 20\n",
      "Percentage of Test Set that were 'Miracles': 11.17%\n"
     ]
    }
   ],
   "source": [
    "# Create a summary of the Test Set results\n",
    "test_results = pd.DataFrame({\n",
    "    'Actual': y_test.flatten(),\n",
    "    'Predicted': y_test_pred\n",
    "})\n",
    "\n",
    "# Identify \"False Negatives\" (Model thought they died, but they lived)\n",
    "miracles = test_results[(test_results['Actual'] == 1) & (test_results['Predicted'] == 0)]\n",
    "\n",
    "print(f\"Number of 'Miracles' in Test Set: {len(miracles)}\")\n",
    "print(f\"Percentage of Test Set that were 'Miracles': {(len(miracles)/len(y_test)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d673b319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Model Test Accuracy: 81.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Initialize the professional model\n",
    "# We use 'liblinear' or 'lbfgs' solvers which are faster versions of our gradient descent\n",
    "sklearn_model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# 2. Train (Fit) the model ONLY on the training data\n",
    "sklearn_model.fit(X_train, y_train.ravel()) # .ravel() flattens y to a 1D array\n",
    "\n",
    "# 3. Predict on the Test Set\n",
    "y_sklearn_pred = sklearn_model.predict(X_test)\n",
    "\n",
    "# 4. Calculate Test Accuracy\n",
    "sklearn_test_acc = accuracy_score(y_test, y_sklearn_pred)\n",
    "\n",
    "print(f\"Sklearn Model Test Accuracy: {sklearn_test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcc35344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Sklearn Health Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.82      0.87      0.84       105\n",
      "    Survived       0.79      0.73      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Final Sklearn Report\n",
    "report_sklearn = classification_report(y_test, y_sklearn_pred, target_names=['Died', 'Survived'])\n",
    "print(\"--- Final Sklearn Health Report ---\")\n",
    "print(report_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f32955",
   "metadata": {},
   "source": [
    "The Final Performance Audit\n",
    "\n",
    "This report is the \"transcript\" of your model's final exam. Let's break down what these specific numbers tell us about the Titanic disaster.\n",
    "### 9.1 The \"Precision-Recall\" Balance\n",
    "\n",
    "    Precision (0.79 for Survived): When the model \"bets\" that a passenger survived, it is right 79% of the time. This means it is relatively cautious; it doesn't hand out survival predictions lightly.\n",
    "\n",
    "    Recall (0.73 for Survived): This is the \"Capture Rate.\" It found 73% of the people who actually lived. The remaining 27% are those \"Miracles\" we discussed—people the math said should have died based on their class or gender, but who managed to survive anyway.\n",
    "\n",
    "### 9.2 The \"Died\" Advantage\n",
    "\n",
    "Notice the F1-Score (0.84) for the \"Died\" category.\n",
    "\n",
    "    Why is it higher? Because death on the Titanic was, unfortunately, more \"predictable\" and statistically common than survival. The model has more examples of what led to death (3rd class, male, older age) than it has for the varied ways people survived.\n",
    "\n",
    "## 9.3 Why Both Models Hit 81%\n",
    "\n",
    "Since your Scratch Model and Sklearn both landed on an 81% accuracy, it proves you have reached the Linear Limit of this dataset.\n",
    "\n",
    "A \"Linear Model\" like Logistic Regression is like drawing a straight line through a cloud of data. You've positioned that line as perfectly as possible. To get to 85% or 90%, you would need a model that can draw \"curves\" or \"zigzag\" lines—like a Random Forest or a Neural Network.\n",
    "## Final Revision Check: The 3 Big Wins\n",
    "\n",
    "    Verified Math: You implemented Gradient Descent from scratch and matched the industry standard.\n",
    "\n",
    "    Clean Generalization: Your model passed the \"Train-Test Split\" exam without crashing in accuracy.\n",
    "\n",
    "    Actionable Insights: You identified that Gender and Class were the strongest features driving the survival predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
